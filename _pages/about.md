---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I'm a first-year Ph.D. student in Management at University of London. I'm a member of the Zing Lab led by [Prof. Mu Yang](https://www.bbk.ac.uk/our-staff/profile/9356136/mu-yang) and [Prof. Chunjia Han](https://www.bbk.ac.uk/our-staff/profile/9337799/chunjia-han) at Clore Management Center, and I am rather fortunate to be jointly advised both of talented scholars. My primary research interests are AI tools', such as Multimodal Foundation Models', application in marketing science and behaviour study. Before UofL, I was fortunate to develop machine learning and multimodal learning skill sets at Columbia University Digital Video and Multimodal Lab with [Hammad Ayyubi](https://hammad001.github.io), instructed by [Prof. Shih-Fu Chang](https://www.engineering.columbia.edu/faculty-staff/directory/dean-shih-fu-chang).

I am broadly open to collaborations that aims at employing AI to measure, understand and resolve business research qeustions. Drop me <a href="mailto:xf2219@columbia.edu">an email</a> if you are interested!

<!--My research spans several fields of machine learning, including representation learning and deep learning frameworks design (e.g. Transformers), as well as Monte Carlo methods. Despite such diversity, I'm chiefly fond of the **theory-grounded algorithms** with applications in computer vision and robotics. Specifically, my research aims at making algorithms more *efficient* \[[1](#Topographer),[5](#HRF),[7](#OMC)\] and *scalable* \[[4](#Toeplitz),
[6](#GKAT)], as well as designing *simple but effective* \[[2](#SMKD)\] learning algorithms as a *better alternative to traditional heuristics* \[[3](#TANDEM)\].

<!--If you are interested in my research and would like collaboration, please feel free to contact me via email! :) -->

<!--**I'm applying for Fall 2023 CS Ph.D. programs and looking for Spring & Summer 2023 research assistant positions. Feel free to reach out!**-->

<br/>


<h1 id="publications"> Publications</h1>

### <a name="Human-like Image Location/Time Reasoning"></a> 1. **(NAACL findings 2025)** **PuzzleGPT: Emulating Human Puzzle-Solving Ability for Time and Location Prediction**
Hammad Ayyubi\*, **<b>Xuande Feng</b>\**, Junzhang Liu\*, Xudong Lin, Zhecan Wang, Shih-Fu Chang
<br>\[[Paper](https://arxiv.org/pdf/2501.14210)\]


Highlight: We designed a web-search multimodality augmented framework for acurate imagery Location/Time reasoning.


### <a name="VIEW"></a> 2. **(EMNLP 2024)** **VIEWS: Entity-Aware News Video Captioning**
Hammad Ayyubi, Tianqi Liu, Arsha Nagrani, Xudong Lin, Mingda Zhang, Anurag Arnab, Feng Han, Yukun Zhu, <b>Xuande Feng</b>, Kevin Zhang, Jialu Liu, Shih-Fu Chang
<br>\[[Paper](https://arxiv.org/pdf/2501.14210)\]


Highlight: We designed a dataset and built a protocol for news video captioning.


### <a name="How Features Work"></a> 3. **(ICTAI 2022)** **How Features Benefit: Parallel Series Embedding for Multivariate Time Series Forecasting with Transformer**
**<b>Xuande Feng</b>\**, Zonglin Lyu\*
<br>\[[Paper](https://ieeexplore.ieee.org/abstract/document/10098079)\]

<!--<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/ICML2023_front_image.png?raw=true"  width="820px"/>-->

Highlight: We present an new approach to encoder multivariate time series data and achieved over 10% performance improvement over variants such as Informer.
<br><br>

<!--### <a name="SMKD"></a> 2. **(Preprint 2023)** **Supervised Masked Knowledge Distillation for Few-shot Transformers**
***Han Lin**\*, Guangxing Han\*, Jiawei Ma, Shiyuan Huang, Xudong Lin, Shih-Fu Chang*
<br>[Paper coming soon]\[[Code](https://github.com/HL-hanlin/SMKD)\]\[[Slides](https://www.dropbox.com/s/29n9gjgzbqjqqbk/SMKD.pdf?dl=0)\]

<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/SMKD3.png?raw=true"  width="820px"/>

Highlight: We propose a novel framework for few-shot Transformers which incorporates label information into self-distillation. Compared with previous self-supervised methods, we allow intra-class knowledge distillation on both class and patch tokens, and introduce the challenging task of masked patch tokens reconstruction across intra-class images. 
<br><br>

<!--### <a name="TANDEM"></a> 3. **(ICRA 2023)** [**Active Tactile Exploration for 3D Object Recognition**](https://arxiv.org/abs/2209.08772)
*Jingxi Xu\*, **Han Lin\***, Shuran Song, Matei Ciocarlie*
<br>\[[Paper](https://arxiv.org/abs/2209.08772)\]\[[Blog](https://jxu.ai/tandem3d/)\]\[[Video](https://www.youtube.com/watch?v=z_90xVf1-88)\]

<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/TANDEM.png?raw=true" height='340px' width="700px"/>

Highlight: We propose TANDEM3D, a co-training framework for exploration and decision making to 3D object recognition with tactile signals. TANDEM3D is based on a novel encoder that builds 3D object representation from contact positions and normals using PointNet++, and enables 6DOF movement.
<br><br>


<!--### <a name="Toeplitz"></a> 4. **(ICML 2022)** [**From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers**](http://arxiv.org/abs/2107.07999)
*Krzysztof Choromanski\*, **Han Lin**\*, Haoxian Chen\*, Tianyi Zhang, Arijit Sehanobish, Valerii Likhosherstov, Jack Parker-Holder, Tamas Sarlos, Adrian Weller, Thomas Weingarten*
<br>\[[Paper](http://arxiv.org/abs/2107.07999)\]\[[Code](https://github.com/HL-hanlin/GKAT)\]\[[Poster](https://icml.cc/media/PosterPDFs/ICML%202022/f231f2107df69eab0a3862d50018a9b2_mzhGQSV.png)\]

<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/Toeplitz.png?raw=true" height='200px'  width="700px"/>

Highlight: We leverage many mathematical techniques ranging from spectral analysis through dynamic programming and random walks and proposed a comprehensive approach for incorporating various masking mechanisms into Transformers architectures in a scalable way, including efficient d-dimensional RPE-masking and graph-kernel masking.
<br><br>

<!--### <a name="HRF"></a> 5. **(ICLR 2022)** [**Hybrid Random Features**](https://arxiv.org/abs/2110.04367)
*Krzysztof Choromanski\*, **Han Lin**\*, Haoxian Chen\*, Yuanzhe Ma\*, Arijit Sehanobish\*, Deepali Jain, Michael S Ryoo, Jake Varley, Andy Zeng, Valerii Likhosherstov, Dmitry Kalashnikov, Vikas Sindhwani, Adrian Weller*
<br>\[[Paper](https://arxiv.org/abs/2110.04367)\]\[[Code](https://github.com/HL-hanlin/HRF_ICLR2022)\]\[[Video](https://iclr.cc/virtual/2022/poster/6410)\]\[[Slides](https://iclr.cc/media/iclr-2022/Slides/6410.pdf)\]

<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/HRF.png?raw=true" width="750px"/>

Highlight: We propose a new class of random feature methods for linearizing softmax and Gaussian kernels called hybrid random features (HRFs) equipted with strong theoretical guarantees - unbiased approximation and strictly smaller worst-case relative errors than its counterparts.
<br><br>

<!--### <a name="GKAT"></a> 6. **(Preprint 2021)** [**Graph Kernel Attention Transformers**](https://github.com/HL-hanlin/GKAT/blob/main/GKAT_16Jul2021.pdf)
*Krzysztof Choromanski\*, **Han Lin**\*, Haoxian Chen\*, Jack Parker-Holder*
<br>\[[Paper](https://github.com/HL-hanlin/GKAT/blob/main/GKAT_16Jul2021.pdf)\]\[[Code](https://github.com/HL-hanlin/GKAT)\]

<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/GKAT.png?raw=true"  width="750px"/>

Highlight: We introduce a new class of graph neural networks, called GKAT, by combining several concepts that were so far studied independently - graph kernels, attention-based networks with structural priors and more recently, efficient Transformers architectures applying small memory footprint implicit attention methods via low rank decomposition techniques.
<br><br>


<!--### <a name="OMC"></a> 7. **(NeurIPS 2020)** [**Demystifying Orthogonal Monte Carlo and Beyond**](https://arxiv.org/abs/2005.13590)
***Han Lin**\*, Haoxian Chen\*, Tianyi Zhang, Clement Laroche, Krzysztof Choromanski*
<br>\[[Paper](https://arxiv.org/abs/2005.13590)\]\[[Code](https://github.com/HL-hanlin/OMC)\]\[[Video](https://slideslive.com/38936089/demystifying-orthogonal-monte-carlo-and-beyond?ref=search-presentations-orthogonal+monte+carlo+and+be)\]
<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/OMC.png?raw=true"  width="700px"/>

<img align='center' src="https://github.com/HL-hanlin/HL-hanlin.github.io/blob/master/images/OMC2.png?raw=true"  width="700px"/>

Highlight: In this paper we shed new light on the theoretical principles behind Orthogonal Monte Carlo (OMC), applying theory of negatively dependent random variables to obtain several new concentration results. We also propose a novel extensions of the method leveraging number theory techniques and particle algorithms, called Near-Orthogonal Monte Carlo (NOMC).
<br><br>

\* Co-First Authors, Equal Contribution.\\
<!--Slideslive video recording and conference poster presenter for \[[5](https://iclr.cc/virtual/2022/poster/6410), [7](https://slideslive.com/38936089/demystifying-orthogonal-monte-carlo-and-beyond?ref=search-presentations-orthogonal+monte+carlo+and+be)\]. \\Github code maintainer for \[[2](https://github.com/HL-hanlin/SMKD), [4](https://github.com/HL-hanlin/GKAT), [5](https://github.com/HL-hanlin/HRF_ICLR2022), [7](https://github.com/HL-hanlin/OMC)\], contributor for \[[3](https://jxu.ai/tandem3d/)\].-->

<br />



<h1 id="teaching"> Teaching Assistants</h1>
### University of Londong:
- [Economic and Financial Metrices], Spring 2025
  - Prof. Zacharias Psaradakis, Department of Finance
  
### Columbia University:
- [IEOR 4752 Forecasting: A Real-World Application](https://www.coursicle.com/columbia/courses/IEOR/), Fall 2022
  - Prof. Syed, Department of IEOR, Columbia University
- [IEOR 4540 Data Mining](https://www.coursicle.com/columbia/courses/IEOR/E4540/), Fall 2022
  - Prof. Krzysztof Choromanski, Department of IEOR, Columbia University


<br />



<h1 id="services"> Academic Services</h1>


<!--%%- Conference Reviewer: ICML 2022, 2023; NeurIPS 2022-->
<!--%%- Conference Volunteer: RSS 2022-->


